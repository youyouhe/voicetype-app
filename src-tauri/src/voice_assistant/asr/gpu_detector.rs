use crate::voice_assistant::asr::whisper_rs::WhisperBackend;
use std::sync::{Mutex, OnceLock};

/// GPUåç«¯æ£€æµ‹å™¨ï¼Œç”¨äºæ£€æµ‹ç³»ç»Ÿä¸­å¯ç”¨çš„GPUåŠ é€Ÿåç«¯
#[derive(Clone)]
pub struct GpuDetector {
    available_backends: Vec<WhisperBackend>,
    preferred_backend: WhisperBackend,
}

impl GpuDetector {
    /// åˆ›å»ºæ–°çš„GPUæ£€æµ‹å™¨å¹¶è‡ªåŠ¨æ£€æµ‹å¯ç”¨åç«¯
    pub fn new() -> Self {
        let mut detector = Self {
            available_backends: Vec::new(),
            preferred_backend: WhisperBackend::CPU,
        };
        
        detector.detect_available_backends();
        detector.select_preferred_backend();
        
        detector
    }
    
    /// æ£€æµ‹ç³»ç»Ÿä¸­å¯ç”¨çš„GPUåç«¯
    fn detect_available_backends(&mut self) {
        println!("ğŸ” Starting comprehensive GPU backend detection...");

        // 1. æ£€æµ‹CUDA (NVIDIA GPU)
        println!("   ğŸ“‹ Checking CUDA support (NVIDIA GPUs)...");
        if self.detect_cuda() {
            self.available_backends.push(WhisperBackend::CUDA);
            println!("âœ… CUDA backend detected - Highest performance option");
        } else {
            println!("   âŒ CUDA not available");
        }

        // 2. æ£€æµ‹Vulkan (è·¨å‚å•†GPU)
        println!("   ğŸ“‹ Checking Vulkan support (Cross-vendor GPUs)...");
        if self.detect_vulkan() {
            self.available_backends.push(WhisperBackend::Vulkan);
            println!("âœ… Vulkan backend detected - Good performance compatibility");
        } else {
            println!("   âŒ Vulkan not available");
        }

        // 3. æ£€æµ‹Metal (Apple Silicon)
        println!("   ğŸ“‹ Checking Metal support (Apple Silicon)...");
        if self.detect_metal() {
            self.available_backends.push(WhisperBackend::Metal);
            println!("âœ… Metal backend detected - Optimized for Apple Silicon");
        } else {
            println!("   âŒ Metal not available");
        }

        // 4. æ£€æµ‹OpenCL (ä½œä¸ºfallback)
        println!("   ğŸ“‹ Checking OpenCL support (Legacy GPUs)...");
        if self.detect_opencl() {
            self.available_backends.push(WhisperBackend::OpenCL);
            println!("âœ… OpenCL backend detected - Fallback for older GPUs");
        } else {
            println!("   âŒ OpenCL not available");
        }

        // 5. CPUæ€»æ˜¯å¯ç”¨
        self.available_backends.push(WhisperBackend::CPU);
        println!("âœ… CPU backend always available - Baseline performance");

        println!("ğŸ¯ GPU backend detection completed. Found {} total backends.", self.available_backends.len());
    }
    
    /// æ£€æµ‹CUDAæ”¯æŒ
    fn detect_cuda(&self) -> bool {
        // Simplified CUDA detection for Windows - avoid hanging on external commands
        if crate::utils::platform::is_windows() {
            // Only check file paths on Windows to avoid command hanging
            let cuda_paths = vec![
                "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA",
                "C:\\Program Files (x86)\\NVIDIA GPU Computing Toolkit\\CUDA",
                "C:\\CUDA",
            ];

            for path in &cuda_paths {
                if std::path::Path::new(path).exists() {
                    println!("ğŸ¯ CUDA installation found at: {}", path);
                    return true;
                }
            }

            // Quick check for NVIDIA driver files
            if std::path::Path::new("C:\\Windows\\System32\\nvidia-smi.exe").exists() {
                println!("ğŸš€ NVIDIA GPU detected via nvidia-smi.exe presence");
                return true;
            }
        } else {
            // On Linux/macOS, try nvidia-smi with timeout
            match std::process::Command::new("nvidia-smi")
                .output()
                .ok() {
                Some(output) if output.status.success() => {
                    let output_str = String::from_utf8_lossy(&output.stdout);
                    if output_str.contains("NVIDIA-SMI") && output_str.contains("Driver Version") {
                        println!("ğŸš€ NVIDIA GPU detected via nvidia-smi");
                        return true;
                    }
                }
                _ => {}
            }

            // Check for CUDA paths
            let cuda_paths = vec!["/usr/local/cuda", "/opt/cuda", "/usr/cuda"];
            for path in &cuda_paths {
                if std::path::Path::new(path).exists() {
                    println!("ğŸ¯ CUDA installation found at: {}", path);
                    return true;
                }
            }
        }

        false
    }
    
    /// æ£€æµ‹Vulkanæ”¯æŒ
    fn detect_vulkan(&self) -> bool {
        // Simplified Vulkan detection - only check for DLL files on Windows to avoid hanging
        let vulkan_libs = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Windows\\System32\\vulkan-1.dll",
                "C:\\Windows\\SysWOW64\\vulkan-1.dll",
            ]
        } else {
            vec![
                "/usr/lib/x86_64-linux-gnu/libvulkan.so.1",
                "/usr/lib/x86_64-linux-gnu/libvulkan.so",
                "/usr/lib/libvulkan.so.1",
                "/usr/lib/libvulkan.so",
            ]
        };

        for lib_path in &vulkan_libs {
            if std::path::Path::new(lib_path).exists() {
                println!("ğŸ® Vulkan library found at: {}", lib_path);
                return true;
            }
        }

        false
    }
    
    /// æ£€æµ‹Metalæ”¯æŒ (macOS Apple Silicon)
    fn detect_metal(&self) -> bool {
        // Metalåªåœ¨macOSä¸Šå¯ç”¨ - simple check without external commands
        if std::env::consts::OS.contains("macos") {
            // Assume Metal is available on all modern macOS versions
            println!("ğŸ Metal assumed available on macOS");
            return true;
        }
        false
    }
    
    /// æ£€æµ‹OpenCLæ”¯æŒ
    fn detect_opencl(&self) -> bool {
        // Simplified OpenCL detection - check only common DLL files
        let opencl_libs = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Windows\\System32\\OpenCL.dll",
                "C:\\Windows\\SysWOW64\\OpenCL.dll",
            ]
        } else {
            vec![
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so.1",
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so",
                "/usr/lib/libOpenCL.so.1",
                "/usr/lib/libOpenCL.so",
            ]
        };

        for lib_path in &opencl_libs {
            if std::path::Path::new(lib_path).exists() {
                println!("âš¡ OpenCL library found at: {}", lib_path);
                return true;
            }
        }

        false
    }
    
    /// æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³åç«¯: CUDA > Vulkan > Metal > OpenCL > CPU
    fn select_preferred_backend(&mut self) {
        self.preferred_backend = self.available_backends
            .iter()
            .cloned()
            .min_by(|a, b| self.backend_priority(a).cmp(&self.backend_priority(b)))
            .unwrap_or(WhisperBackend::CPU);
    }
    
    /// è·å–åç«¯ä¼˜å…ˆçº§ (æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜)
    pub fn backend_priority(&self, backend: &WhisperBackend) -> u8 {
        match backend {
            WhisperBackend::CUDA => 1,      // æœ€é«˜ä¼˜å…ˆçº§
            WhisperBackend::Vulkan => 2,    // ç¬¬äºŒä¼˜å…ˆçº§
            WhisperBackend::Metal => 3,     // Apple Siliconä¼˜å…ˆçº§
            WhisperBackend::OpenCL => 4,    // Fallback
            WhisperBackend::CPU => 5,       // æœ€ä½ä¼˜å…ˆçº§
        }
    }
    
    /// è·å–é¦–é€‰åç«¯
    pub fn get_preferred_backend(&self) -> &WhisperBackend {
        &self.preferred_backend
    }
    
    /// è·å–æ‰€æœ‰å¯ç”¨åç«¯
    pub fn get_available_backends(&self) -> &[WhisperBackend] {
        &self.available_backends
    }
    
    /// æ£€æŸ¥ç‰¹å®šåç«¯æ˜¯å¦å¯ç”¨
    pub fn is_backend_available(&self, backend: &WhisperBackend) -> bool {
        self.available_backends.contains(backend)
    }
    
    /// æ‰‹åŠ¨è®¾ç½®é¦–é€‰åç«¯
    pub fn set_preferred_backend(&mut self, backend: WhisperBackend) -> Result<(), String> {
        if self.is_backend_available(&backend) {
            self.preferred_backend = backend.clone();
            println!("ğŸ¯ Preferred backend manually set to: {}", backend);
            Ok(())
        } else {
            Err(format!("Backend {} is not available", backend))
        }
    }
    
    /// è·å–åç«¯ä¿¡æ¯å­—ç¬¦ä¸²
    pub fn get_backend_info(&self) -> String {
        format!(
            "Available backends: [{}], Preferred: {}",
            self.available_backends
                .iter()
                .map(|b| b.to_string())
                .collect::<Vec<_>>()
                .join(", "),
            self.preferred_backend
        )
    }
}

/// å…¨å±€GPUæ£€æµ‹å™¨å®ä¾‹
static GLOBAL_GPU_DETECTOR: OnceLock<Mutex<GpuDetector>> = OnceLock::new();

/// è·å–å…¨å±€GPUæ£€æµ‹å™¨
pub fn get_gpu_detector() -> &'static Mutex<GpuDetector> {
    GLOBAL_GPU_DETECTOR.get_or_init(|| Mutex::new(GpuDetector::new()))
}

/// é‡æ–°æ£€æµ‹GPUåç«¯
pub fn redetect_gpu_backends() -> &'static Mutex<GpuDetector> {
    let new_detector = GpuDetector::new();
    let detector = get_gpu_detector();
    let mut guard = detector.lock().unwrap();
    *guard = new_detector;
    detector
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_gpu_detector_creation() {
        let detector = GpuDetector::new();
        assert!(!detector.get_available_backends().is_empty());
        assert!(detector.is_backend_available(&WhisperBackend::Cpu));
    }
    
    #[test]
    fn test_backend_priority() {
        let detector = GpuDetector::new();
        assert_eq!(detector.backend_priority(&WhisperBackend::CUDA), 1);
        assert_eq!(detector.backend_priority(&WhisperBackend::Vulkan), 2);
        assert_eq!(detector.backend_priority(&WhisperBackend::CPU), 5);
    }
}