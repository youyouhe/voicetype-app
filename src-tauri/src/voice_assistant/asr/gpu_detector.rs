use crate::voice_assistant::asr::whisper_rs::WhisperBackend;
use std::process::Command;
use std::sync::{Mutex, OnceLock};

/// GPUåç«¯æ£€æµ‹å™¨ï¼Œç”¨äºæ£€æµ‹ç³»ç»Ÿä¸­å¯ç”¨çš„GPUåŠ é€Ÿåç«¯
#[derive(Clone)]
pub struct GpuDetector {
    available_backends: Vec<WhisperBackend>,
    preferred_backend: WhisperBackend,
}

impl GpuDetector {
    /// åˆ›å»ºæ–°çš„GPUæ£€æµ‹å™¨å¹¶è‡ªåŠ¨æ£€æµ‹å¯ç”¨åç«¯
    pub fn new() -> Self {
        let mut detector = Self {
            available_backends: Vec::new(),
            preferred_backend: WhisperBackend::CPU,
        };
        
        detector.detect_available_backends();
        detector.select_preferred_backend();
        
        detector
    }
    
    /// æ£€æµ‹ç³»ç»Ÿä¸­å¯ç”¨çš„GPUåç«¯
    fn detect_available_backends(&mut self) {
        println!("ğŸ” Starting comprehensive GPU backend detection...");

        // 1. æ£€æµ‹CUDA (NVIDIA GPU)
        println!("   ğŸ“‹ Checking CUDA support (NVIDIA GPUs)...");
        if self.detect_cuda() {
            self.available_backends.push(WhisperBackend::CUDA);
            println!("âœ… CUDA backend detected - Highest performance option");
        } else {
            println!("   âŒ CUDA not available");
        }

        // 2. æ£€æµ‹Vulkan (è·¨å‚å•†GPU)
        println!("   ğŸ“‹ Checking Vulkan support (Cross-vendor GPUs)...");
        if self.detect_vulkan() {
            self.available_backends.push(WhisperBackend::Vulkan);
            println!("âœ… Vulkan backend detected - Good performance compatibility");
        } else {
            println!("   âŒ Vulkan not available");
        }

        // 3. æ£€æµ‹Metal (Apple Silicon)
        println!("   ğŸ“‹ Checking Metal support (Apple Silicon)...");
        if self.detect_metal() {
            self.available_backends.push(WhisperBackend::Metal);
            println!("âœ… Metal backend detected - Optimized for Apple Silicon");
        } else {
            println!("   âŒ Metal not available");
        }

        // 4. æ£€æµ‹OpenCL (ä½œä¸ºfallback)
        println!("   ğŸ“‹ Checking OpenCL support (Legacy GPUs)...");
        if self.detect_opencl() {
            self.available_backends.push(WhisperBackend::OpenCL);
            println!("âœ… OpenCL backend detected - Fallback for older GPUs");
        } else {
            println!("   âŒ OpenCL not available");
        }

        // 5. CPUæ€»æ˜¯å¯ç”¨
        self.available_backends.push(WhisperBackend::CPU);
        println!("âœ… CPU backend always available - Baseline performance");

        println!("ğŸ¯ GPU backend detection completed. Found {} total backends.", self.available_backends.len());
    }
    
    /// æ£€æµ‹CUDAæ”¯æŒ
    fn detect_cuda(&self) -> bool {
        // æ–¹æ³•1: æ£€æŸ¥nvidia-smiå‘½ä»¤
        let nvidia_cmd = if crate::utils::platform::is_windows() { "nvidia-smi.exe" } else { "nvidia-smi" };
        if let Ok(output) = Command::new(nvidia_cmd).output() {
            if output.status.success() {
                let output_str = String::from_utf8_lossy(&output.stdout);
                if output_str.contains("NVIDIA-SMI") && output_str.contains("Driver Version") {
                    println!("ğŸš€ NVIDIA GPU detected via nvidia-smi");
                    return true;
                }
            }
        }
        
        // æ–¹æ³•2: æ£€æŸ¥CUDAåº“æ–‡ä»¶
        let cuda_paths = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA",
                "C:\\Program Files (x86)\\NVIDIA GPU Computing Toolkit\\CUDA",
                "C:\\CUDA",
            ]
        } else {
            vec![
                "/usr/local/cuda",
                "/opt/cuda",
                "/usr/cuda",
            ]
        };

        for path in &cuda_paths {
            if std::path::Path::new(path).exists() {
                println!("ğŸ¯ CUDA installation found at: {}", path);
                return true;
            }
        }
        
        // æ–¹æ³•3: æ£€æŸ¥CUDAç¯å¢ƒå˜é‡
        let cuda_env_vars = crate::utils::platform::get_cuda_env_vars();
        for var in &cuda_env_vars {
            if std::env::var(var).is_ok() {
                println!("ğŸ”§ CUDA environment variables detected");
                return true;
            }
        }
        
        false
    }
    
    /// æ£€æµ‹Vulkanæ”¯æŒ
    fn detect_vulkan(&self) -> bool {
        // æ–¹æ³•1: æ£€æŸ¥vulkaninfoå‘½ä»¤
        let vulkan_cmd = if crate::utils::platform::is_windows() { "vulkaninfo.exe" } else { "vulkaninfo" };
        if let Ok(output) = Command::new(vulkan_cmd).output() {
            if output.status.success() {
                let output_str = String::from_utf8_lossy(&output.stdout);
                if output_str.contains("Vulkan Instance") || output_str.contains("VkInstance") {
                    println!("ğŸ® Vulkan detected via vulkaninfo");
                    return true;
                }
            }
        }

        // æ–¹æ³•2: æ£€æŸ¥Vulkanåº“æ–‡ä»¶
        let vulkan_libs = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Windows\\System32\\vulkan-1.dll",
                "C:\\Program Files\\VulkanSDK\\1.3.283.0\\Bin\\vulkan-1.dll",
                "C:\\VulkanSDK\\1.3.283.0\\Bin\\vulkan-1.dll",
                "C:\\Program Files (x86)\\VulkanSDK\\1.3.283.0\\Bin\\vulkan-1.dll",
            ]
        } else {
            vec![
                "/usr/lib/x86_64-linux-gnu/libvulkan.so.1",
                "/usr/lib/x86_64-linux-gnu/libvulkan.so",
                "/usr/lib/libvulkan.so.1",
                "/usr/lib/libvulkan.so",
            ]
        };

        for lib_path in &vulkan_libs {
            if std::path::Path::new(lib_path).exists() {
                println!("ğŸ”§ Vulkan library found at: {}", lib_path);
                return true;
            }
        }
        
        false
    }
    
    /// æ£€æµ‹Metalæ”¯æŒ (macOS Apple Silicon)
    fn detect_metal(&self) -> bool {
        // Metalåªåœ¨macOSä¸Šå¯ç”¨
        if !std::env::consts::OS.contains("macos") {
            return false;
        }
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºApple Silicon
        if let Ok(output) = Command::new("uname").arg("-m").output() {
            if output.status.success() {
                let output_str = String::from_utf8_lossy(&output.stdout);
                if output_str.contains("arm64") {
                    println!("ğŸ Metal detected on Apple Silicon");
                    return true;
                }
            }
        }
        
        false
    }
    
    /// æ£€æµ‹OpenCLæ”¯æŒ
    fn detect_opencl(&self) -> bool {
        // æ£€æŸ¥OpenCLåº“
        let opencl_libs = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Windows\\System32\\OpenCL.dll",
                "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v*\\bin\\OpenCL.dll",
                "C:\\Program Files\\AMD\\ROCm\\*\\bin\\OpenCL.dll",
                "C:\\Program Files (x86)\\AMD\\APP\\*\\bin\\x86_64\\OpenCL.dll",
                "C:\\Program Files\\Intel\\OpenCL SDK\\*\\bin\\x64\\OpenCL.dll",
            ]
        } else {
            vec![
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so.1",
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so",
                "/usr/lib/libOpenCL.so.1",
                "/usr/lib/libOpenCL.so",
            ]
        };

        for lib_path in &opencl_libs {
            // Handle wildcards in Windows paths
            if lib_path.contains('*') {
                if crate::utils::platform::is_windows() {
                    // For simplicity, just check if the directory exists
                    if let Some(parent) = std::path::Path::new(lib_path).parent() {
                        if parent.exists() {
                            println!("âš¡ OpenCL directory found at: {}", parent.display());
                            return true;
                        }
                    }
                }
            } else if std::path::Path::new(lib_path).exists() {
                println!("âš¡ OpenCL library found at: {}", lib_path);
                return true;
            }
        }

        false
    }
    
    /// æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³åç«¯: CUDA > Vulkan > Metal > OpenCL > CPU
    fn select_preferred_backend(&mut self) {
        self.preferred_backend = self.available_backends
            .iter()
            .cloned()
            .min_by(|a, b| self.backend_priority(a).cmp(&self.backend_priority(b)))
            .unwrap_or(WhisperBackend::CPU);
    }
    
    /// è·å–åç«¯ä¼˜å…ˆçº§ (æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜)
    pub fn backend_priority(&self, backend: &WhisperBackend) -> u8 {
        match backend {
            WhisperBackend::CUDA => 1,      // æœ€é«˜ä¼˜å…ˆçº§
            WhisperBackend::Vulkan => 2,    // ç¬¬äºŒä¼˜å…ˆçº§
            WhisperBackend::Metal => 3,     // Apple Siliconä¼˜å…ˆçº§
            WhisperBackend::OpenCL => 4,    // Fallback
            WhisperBackend::CPU => 5,       // æœ€ä½ä¼˜å…ˆçº§
        }
    }
    
    /// è·å–é¦–é€‰åç«¯
    pub fn get_preferred_backend(&self) -> &WhisperBackend {
        &self.preferred_backend
    }
    
    /// è·å–æ‰€æœ‰å¯ç”¨åç«¯
    pub fn get_available_backends(&self) -> &[WhisperBackend] {
        &self.available_backends
    }
    
    /// æ£€æŸ¥ç‰¹å®šåç«¯æ˜¯å¦å¯ç”¨
    pub fn is_backend_available(&self, backend: &WhisperBackend) -> bool {
        self.available_backends.contains(backend)
    }
    
    /// æ‰‹åŠ¨è®¾ç½®é¦–é€‰åç«¯
    pub fn set_preferred_backend(&mut self, backend: WhisperBackend) -> Result<(), String> {
        if self.is_backend_available(&backend) {
            self.preferred_backend = backend.clone();
            println!("ğŸ¯ Preferred backend manually set to: {}", backend);
            Ok(())
        } else {
            Err(format!("Backend {} is not available", backend))
        }
    }
    
    /// è·å–åç«¯ä¿¡æ¯å­—ç¬¦ä¸²
    pub fn get_backend_info(&self) -> String {
        format!(
            "Available backends: [{}], Preferred: {}",
            self.available_backends
                .iter()
                .map(|b| b.to_string())
                .collect::<Vec<_>>()
                .join(", "),
            self.preferred_backend
        )
    }
}

/// å…¨å±€GPUæ£€æµ‹å™¨å®ä¾‹
static GLOBAL_GPU_DETECTOR: OnceLock<Mutex<GpuDetector>> = OnceLock::new();

/// è·å–å…¨å±€GPUæ£€æµ‹å™¨
pub fn get_gpu_detector() -> &'static Mutex<GpuDetector> {
    GLOBAL_GPU_DETECTOR.get_or_init(|| Mutex::new(GpuDetector::new()))
}

/// é‡æ–°æ£€æµ‹GPUåç«¯
pub fn redetect_gpu_backends() -> &'static Mutex<GpuDetector> {
    let new_detector = GpuDetector::new();
    let detector = get_gpu_detector();
    let mut guard = detector.lock().unwrap();
    *guard = new_detector;
    detector
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_gpu_detector_creation() {
        let detector = GpuDetector::new();
        assert!(!detector.get_available_backends().is_empty());
        assert!(detector.is_backend_available(&WhisperBackend::CPU));
    }
    
    #[test]
    fn test_backend_priority() {
        let detector = GpuDetector::new();
        assert_eq!(detector.backend_priority(&WhisperBackend::CUDA), 1);
        assert_eq!(detector.backend_priority(&WhisperBackend::Vulkan), 2);
        assert_eq!(detector.backend_priority(&WhisperBackend::CPU), 5);
    }
}