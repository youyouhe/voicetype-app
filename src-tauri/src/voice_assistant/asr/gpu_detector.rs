use crate::voice_assistant::asr::whisper_rs::WhisperBackend;
use std::sync::{Mutex, OnceLock};

/// GPUåç«¯æ£€æµ‹å™¨ï¼Œç”¨äºæ£€æµ‹ç³»ç»Ÿä¸­å¯ç”¨çš„GPUåŠ é€Ÿåç«¯
#[derive(Clone)]
pub struct GpuDetector {
    available_backends: Vec<WhisperBackend>,
    preferred_backend: WhisperBackend,
}

impl GpuDetector {
    /// åˆ›å»ºæ–°çš„GPUæ£€æµ‹å™¨å¹¶è‡ªåŠ¨æ£€æµ‹å¯ç”¨åç«¯
    pub fn new() -> Self {
        let mut detector = Self {
            available_backends: Vec::new(),
            preferred_backend: WhisperBackend::CPU,
        };
        
        detector.detect_available_backends();
        detector.select_preferred_backend();
        
        detector
    }
    
    /// æ£€æµ‹ç³»ç»Ÿä¸­å¯ç”¨çš„GPUåç«¯
    fn detect_available_backends(&mut self) {
        println!("ğŸ” Starting comprehensive GPU backend detection...");

        // 1. æ£€æµ‹CUDA (NVIDIA GPU)
        println!("   ğŸ“‹ Checking CUDA support (NVIDIA GPUs)...");
        if self.detect_cuda() {
            self.available_backends.push(WhisperBackend::CUDA);
            println!("âœ… CUDA backend detected - Highest performance option");
        } else {
            println!("   âŒ CUDA not available");
        }

        // 2. æ£€æµ‹Vulkan (è·¨å‚å•†GPU)
        println!("   ğŸ“‹ Checking Vulkan support (Cross-vendor GPUs)...");
        if self.detect_vulkan() {
            self.available_backends.push(WhisperBackend::Vulkan);
            println!("âœ… Vulkan backend detected - Good performance compatibility");
        } else {
            println!("   âŒ Vulkan not available");
        }

        // 3. æ£€æµ‹Metal (Apple Silicon)
        println!("   ğŸ“‹ Checking Metal support (Apple Silicon)...");
        if self.detect_metal() {
            self.available_backends.push(WhisperBackend::Metal);
            println!("âœ… Metal backend detected - Optimized for Apple Silicon");
        } else {
            println!("   âŒ Metal not available");
        }

        // 4. æ£€æµ‹OpenCL (ä½œä¸ºfallback)
        println!("   ğŸ“‹ Checking OpenCL support (Legacy GPUs)...");
        if self.detect_opencl() {
            self.available_backends.push(WhisperBackend::OpenCL);
            println!("âœ… OpenCL backend detected - Fallback for older GPUs");
        } else {
            println!("   âŒ OpenCL not available");
        }

        // 5. CPUæ€»æ˜¯å¯ç”¨
        self.available_backends.push(WhisperBackend::CPU);
        println!("âœ… CPU backend always available - Baseline performance");

        println!("ğŸ¯ GPU backend detection completed. Found {} total backends.", self.available_backends.len());
    }
    
    /// æ£€æµ‹CUDAæ”¯æŒ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«è¿è¡Œæ—¶æ£€æŸ¥
    fn detect_cuda(&self) -> bool {
        if crate::utils::platform::is_windows() {
            // Windows CUDAæ£€æµ‹

            // 1. æ£€æŸ¥NVIDIAé©±åŠ¨
            if std::path::Path::new("C:\\Windows\\System32\\nvidia-smi.exe").exists() {
                println!("ğŸš€ NVIDIA driver detected");

                // å°è¯•è·å–GPUä¿¡æ¯
                match std::process::Command::new("C:\\Windows\\System32\\nvidia-smi.exe")
                    .args(&["--query-gpu=name,driver_version,memory.total", "--format=csv,noheader,nounits"])
                    .output()
                    .ok() {
                    Some(output) if output.status.success() => {
                        let gpu_info = String::from_utf8_lossy(&output.stdout);
                        println!("ğŸ’¾ NVIDIA GPU Info:\n{}", gpu_info);

                        // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ˜¾å­˜ï¼ˆå»ºè®®è‡³å°‘4GBï¼‰
                        if gpu_info.lines().any(|line| {
                            line.split(',').nth(2).unwrap_or("0").trim().parse::<u32>().unwrap_or(0) >= 4096
                        }) {
                            println!("âœ… Sufficient GPU memory detected for CUDA acceleration");
                        } else {
                            println!("âš ï¸ Limited GPU memory - CUDA may still work but could be slow");
                        }
                    }
                    _ => {
                        println!("âš ï¸ Could not query GPU details");
                    }
                }

                // 2. æ£€æŸ¥CUDA Toolkitå®‰è£…
                let cuda_paths = vec![
                    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.0",
                    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8",
                    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7",
                    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA",
                    "C:\\Program Files (x86)\\NVIDIA GPU Computing Toolkit\\CUDA",
                    "C:\\CUDA",
                ];

                for path in &cuda_paths {
                    if std::path::Path::new(path).exists() {
                        println!("ğŸ¯ CUDA Toolkit found at: {}", path);

                        // æ£€æŸ¥å…³é”®åº“æ–‡ä»¶
                        let cudart_path = format!("{}\\bin\\cudart64_*.dll", path);
                        if glob::glob(&cudart_path).unwrap().next().is_some() {
                            println!("âœ… CUDA runtime libraries found");
                            return true;
                        } else {
                            println!("âš ï¸ CUDA Toolkit found but runtime libraries missing");
                        }
                    }
                }

                // 3. æ£€æŸ¥ç³»ç»ŸPATHä¸­çš„CUDAè¿è¡Œæ—¶
                if self.check_cuda_runtime_in_path() {
                    return true;
                }

                println!("ğŸ”§ CUDA driver found but Toolkit installation not detected");
                println!("ğŸ’¡ Install NVIDIA CUDA Toolkit for better performance");
                println!("   Download: https://developer.nvidia.com/cuda-downloads");
                return true; // æœ‰é©±åŠ¨å°±å¯ä»¥å°è¯•ä½¿ç”¨CUDA
            } else {
                println!("âŒ NVIDIA driver not found");
                return false;
            }
        } else {
            // Linux/macOS CUDAæ£€æµ‹
            match std::process::Command::new("nvidia-smi")
                .output()
                .ok() {
                Some(output) if output.status.success() => {
                    let output_str = String::from_utf8_lossy(&output.stdout);
                    if output_str.contains("NVIDIA-SMI") && output_str.contains("Driver Version") {
                        println!("ğŸš€ NVIDIA GPU detected via nvidia-smi");

                        // æå–GPUä¿¡æ¯
                        if let Some(gpu_line) = output_str.lines().find(|line| line.contains("CUDA Version")) {
                            println!("ğŸ“Š GPU Driver: {}", gpu_line.trim());
                        }

                        // æ£€æŸ¥CUDAåº“
                        let cuda_paths = vec!["/usr/local/cuda", "/opt/cuda", "/usr/cuda"];
                        for path in &cuda_paths {
                            if std::path::Path::new(path).exists() {
                                println!("ğŸ¯ CUDA installation found at: {}", path);
                                return true;
                            }
                        }

                        // æ£€æŸ¥ç³»ç»Ÿåº“
                        if self.check_cuda_libraries() {
                            return true;
                        }

                        return true; // æœ‰é©±åŠ¨å°±è¿”å›true
                    }
                }
                _ => {}
            }
        }

        false
    }

    /// æ£€æŸ¥PATHä¸­çš„CUDAè¿è¡Œæ—¶åº“
    fn check_cuda_runtime_in_path(&self) -> bool {
        if let Ok(path_env) = std::env::var("PATH") {
            for path_dir in path_env.split(';') {
                let cudart_candidates = vec![
                    format!("{}\\cudart64_120.dll", path_dir),
                    format!("{}\\cudart64_118.dll", path_dir),
                    format!("{}\\cudart64_117.dll", path_dir),
                    format!("{}\\cudart64_110.dll", path_dir),
                ];

                for cudart_path in cudart_candidates {
                    if std::path::Path::new(&cudart_path).exists() {
                        println!("âœ… CUDA runtime found in PATH: {}", cudart_path);
                        return true;
                    }
                }
            }
        }
        false
    }

    /// æ£€æŸ¥Linuxç³»ç»ŸCUDAåº“
    fn check_cuda_libraries(&self) -> bool {
        let libcuda_paths = vec![
            "/usr/lib/x86_64-linux-gnu/libcudart.so.12",
            "/usr/lib/x86_64-linux-gnu/libcudart.so.11",
            "/usr/lib/libcudart.so.12",
            "/usr/lib/libcudart.so.11",
        ];

        for lib_path in &libcuda_paths {
            if std::path::Path::new(lib_path).exists() {
                println!("âœ… CUDA library found: {}", lib_path);
                return true;
            }
        }
        false
    }
    
    /// æ£€æµ‹Vulkanæ”¯æŒ
    fn detect_vulkan(&self) -> bool {
        // Simplified Vulkan detection - only check for DLL files on Windows to avoid hanging
        let vulkan_libs = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Windows\\System32\\vulkan-1.dll",
                "C:\\Windows\\SysWOW64\\vulkan-1.dll",
            ]
        } else {
            vec![
                "/usr/lib/x86_64-linux-gnu/libvulkan.so.1",
                "/usr/lib/x86_64-linux-gnu/libvulkan.so",
                "/usr/lib/libvulkan.so.1",
                "/usr/lib/libvulkan.so",
            ]
        };

        for lib_path in &vulkan_libs {
            if std::path::Path::new(lib_path).exists() {
                println!("ğŸ® Vulkan library found at: {}", lib_path);
                return true;
            }
        }

        false
    }
    
    /// æ£€æµ‹Metalæ”¯æŒ (macOS Apple Silicon)
    fn detect_metal(&self) -> bool {
        // Metalåªåœ¨macOSä¸Šå¯ç”¨ - simple check without external commands
        if std::env::consts::OS.contains("macos") {
            // Assume Metal is available on all modern macOS versions
            println!("ğŸ Metal assumed available on macOS");
            return true;
        }
        false
    }
    
    /// æ£€æµ‹OpenCLæ”¯æŒ
    fn detect_opencl(&self) -> bool {
        // Simplified OpenCL detection - check only common DLL files
        let opencl_libs = if crate::utils::platform::is_windows() {
            vec![
                "C:\\Windows\\System32\\OpenCL.dll",
                "C:\\Windows\\SysWOW64\\OpenCL.dll",
            ]
        } else {
            vec![
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so.1",
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so",
                "/usr/lib/libOpenCL.so.1",
                "/usr/lib/libOpenCL.so",
            ]
        };

        for lib_path in &opencl_libs {
            if std::path::Path::new(lib_path).exists() {
                println!("âš¡ OpenCL library found at: {}", lib_path);
                return true;
            }
        }

        false
    }
    
    /// æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©æœ€ä½³åç«¯: CUDA > Vulkan > Metal > OpenCL > CPU
    fn select_preferred_backend(&mut self) {
        self.preferred_backend = self.available_backends
            .iter()
            .cloned()
            .min_by(|a, b| self.backend_priority(a).cmp(&self.backend_priority(b)))
            .unwrap_or(WhisperBackend::CPU);
    }
    
    /// è·å–åç«¯ä¼˜å…ˆçº§ (æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜)
    pub fn backend_priority(&self, backend: &WhisperBackend) -> u8 {
        match backend {
            WhisperBackend::CUDA => 1,      // æœ€é«˜ä¼˜å…ˆçº§
            WhisperBackend::Vulkan => 2,    // ç¬¬äºŒä¼˜å…ˆçº§
            WhisperBackend::Metal => 3,     // Apple Siliconä¼˜å…ˆçº§
            WhisperBackend::OpenCL => 4,    // Fallback
            WhisperBackend::CPU => 5,       // æœ€ä½ä¼˜å…ˆçº§
        }
    }
    
    /// è·å–é¦–é€‰åç«¯
    pub fn get_preferred_backend(&self) -> &WhisperBackend {
        &self.preferred_backend
    }
    
    /// è·å–æ‰€æœ‰å¯ç”¨åç«¯
    pub fn get_available_backends(&self) -> &[WhisperBackend] {
        &self.available_backends
    }
    
    /// æ£€æŸ¥ç‰¹å®šåç«¯æ˜¯å¦å¯ç”¨
    pub fn is_backend_available(&self, backend: &WhisperBackend) -> bool {
        self.available_backends.contains(backend)
    }
    
    /// æ‰‹åŠ¨è®¾ç½®é¦–é€‰åç«¯
    pub fn set_preferred_backend(&mut self, backend: WhisperBackend) -> Result<(), String> {
        if self.is_backend_available(&backend) {
            self.preferred_backend = backend.clone();
            println!("ğŸ¯ Preferred backend manually set to: {}", backend);
            Ok(())
        } else {
            Err(format!("Backend {} is not available", backend))
        }
    }
    
    /// è·å–åç«¯ä¿¡æ¯å­—ç¬¦ä¸²
    pub fn get_backend_info(&self) -> String {
        format!(
            "Available backends: [{}], Preferred: {}",
            self.available_backends
                .iter()
                .map(|b| b.to_string())
                .collect::<Vec<_>>()
                .join(", "),
            self.preferred_backend
        )
    }
}

/// å…¨å±€GPUæ£€æµ‹å™¨å®ä¾‹
static GLOBAL_GPU_DETECTOR: OnceLock<Mutex<GpuDetector>> = OnceLock::new();

/// è·å–å…¨å±€GPUæ£€æµ‹å™¨
pub fn get_gpu_detector() -> &'static Mutex<GpuDetector> {
    GLOBAL_GPU_DETECTOR.get_or_init(|| Mutex::new(GpuDetector::new()))
}

/// é‡æ–°æ£€æµ‹GPUåç«¯
pub fn redetect_gpu_backends() -> &'static Mutex<GpuDetector> {
    let new_detector = GpuDetector::new();
    let detector = get_gpu_detector();
    let mut guard = detector.lock().unwrap();
    *guard = new_detector;
    detector
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_gpu_detector_creation() {
        let detector = GpuDetector::new();
        assert!(!detector.get_available_backends().is_empty());
        assert!(detector.is_backend_available(&WhisperBackend::CPU));
    }
    
    #[test]
    fn test_backend_priority() {
        let detector = GpuDetector::new();
        assert_eq!(detector.backend_priority(&WhisperBackend::CUDA), 1);
        assert_eq!(detector.backend_priority(&WhisperBackend::Vulkan), 2);
        assert_eq!(detector.backend_priority(&WhisperBackend::CPU), 5);
    }
}